{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a4d20e-5970-4656-986e-a5201457a4d8",
   "metadata": {},
   "source": [
    "# Unique Canonical Representation\n",
    "\n",
    "A test to determine if alignment procedures construct and align to a unique canonical representation.\n",
    "\n",
    "1. Take a molecular structure from QM9\n",
    "2. Normalize the structure using <METHOD>\n",
    "3. For N times:\n",
    "\n",
    "    i. Transform initial structure\n",
    "   \n",
    "    ii. Normalize transformed structure\n",
    "\n",
    "    iii. Compute Wasserstein distance between structures\n",
    "\n",
    "    iv. Store loss by rank/point group\n",
    "\n",
    "Times are reported by TQDM, average loss is reported by rank/point group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e035910d-bd81-42db-84a9-c2b6127fac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ot  # Python Optimal Transport (POT) library\n",
    "\n",
    "from pointgroup import PointGroup\n",
    "from torch_geometric.datasets import QM9\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d5332-9fb0-43b3-98ca-6d3fef015e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wasserstein_distance(pc1, pc2):\n",
    "    \"\"\"\n",
    "    Compute the Wasserstein distance (EMD) between two point clouds.\n",
    "\n",
    "    Args:\n",
    "    pc1 (torch.Tensor): First point cloud (NxD).\n",
    "    pc2 (torch.Tensor): Second point cloud (MxD).\n",
    "\n",
    "    Returns:\n",
    "    float: The Wasserstein distance.\n",
    "    \"\"\"\n",
    "    # Convert PyTorch tensors to NumPy arrays if necessary\n",
    "    if isinstance(pc1, torch.Tensor):\n",
    "        pc1 = pc1.detach().cpu().numpy()\n",
    "    if isinstance(pc2, torch.Tensor):\n",
    "        pc2 = pc2.detach().cpu().numpy()\n",
    "\n",
    "    # Create uniform distribution for each point cloud\n",
    "    n1, n2 = pc1.shape[0], pc2.shape[0]\n",
    "    a, b = ot.unif(n1), ot.unif(n2)\n",
    "\n",
    "    # Compute cost matrix\n",
    "    M = ot.dist(pc1, pc2, metric='euclidean')\n",
    "\n",
    "    # Compute Wasserstein distance (EMD)\n",
    "    emd_distance = ot.emd2(a, b, M)\n",
    "\n",
    "    return emd_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0a321-369b-4f55-a05b-abdeb1829322",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7d2f55-a893-4e31-8108-ff4132377cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from abc import ABCMeta\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class SVDAlignment(metaclass=ABCMeta):\n",
    "  def __call__(self, pointcloud: Tensor, *args: Any, **kwds: Any) -> Any:\n",
    "    self.pointcloud = pointcloud # (n,m)-dimensional tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "  def align_center(self, pointcloud):\n",
    "    return pointcloud - pointcloud.mean(dim=0)\n",
    "\n",
    "  def get_eigs(self, pointcloud):\n",
    "    C = torch.matmul(pointcloud.t(), pointcloud)\n",
    "    e, v = torch.linalg.eig(C)  # v[:,j] is j-th eigenvector\n",
    "    return torch.view_as_real(e), v.real\n",
    "\n",
    "\n",
    "  def svd_rotate(self, pointcloud):\n",
    "    e, v = self.get_eigs(pointcloud)\n",
    "    indices = e[:, 0].argsort(descending=True)\n",
    "    v = v.t()[indices].t()\n",
    "    return torch.matmul(pointcloud, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d875aa1-cedc-4a46-b3c3-4efde8981724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:22<00:00, 437.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Loss: 1.89805, Rank 2 Loss: 2.10510, Rank 3 Loss: 2.43520\n",
      "\tPoint Group Td : 1.9635413812800062\n",
      "\tPoint Group C3v : 2.4066188267868553\n",
      "\tPoint Group C2v : 2.699401920794461\n",
      "\tPoint Group Dinfh : 2.223506417244732\n",
      "\tPoint Group Cinfv : 2.5627570800703396\n",
      "\tPoint Group D3d : 2.5278595713494263\n",
      "\tPoint Group C1 : 2.3920799210127237\n",
      "\tPoint Group Cs : 2.802666677890567\n",
      "\tPoint Group D3h : 2.1726454635623296\n",
      "\tPoint Group C2 : 2.5476797477799344\n",
      "\tPoint Group C2h : 2.5438649185049442\n",
      "\tPoint Group D2d : 1.9552719477082061\n",
      "\tPoint Group C1v : 2.4932992610916296\n",
      "\tPoint Group C1h : 2.23501501641634\n",
      "\tPoint Group D6h : 2.716527320883651\n",
      "\tPoint Group D2h : 2.672102587412916\n",
      "\tPoint Group C3 : 1.9051950106446491\n",
      "\tPoint Group S2 : 5.055503645681741\n",
      "\tPoint Group C3h : 2.1741920364115215\n",
      "\tPoint Group D3 : 1.596167541153601\n",
      "\tPoint Group Ci : 2.7027557023920594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pointgroup import PointGroup\n",
    "from torch_geometric.datasets import QM9\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "np.random.seed(42)\n",
    "\n",
    "qm9 = QM9(root='../datasets/qm9-2.4.0/')\n",
    "SVDA = SVDAlignment()\n",
    "pg_losses = {}\n",
    "\n",
    "atomic_number_to_symbol = {\n",
    "    1: 'H', 6: 'C', 7: 'N', 8: 'O', 9: 'F'\n",
    "    }\n",
    "\n",
    "\n",
    "rank1_loss, rank1_count = 0,0\n",
    "rank2_loss, rank2_count = 0,0\n",
    "rank3_loss, rank3_count = 0,0\n",
    "\n",
    "for idx,data in enumerate(tqdm(qm9[:10000])):\n",
    "    point_cloud = data.pos\n",
    "    rank = torch.linalg.matrix_rank(point_cloud)\n",
    "    cat_data = data.z.numpy()\n",
    "    SVDA(point_cloud)\n",
    "    normalized_data = SVDA.pointcloud  \n",
    "    \n",
    "    positions = data.pos.numpy()\n",
    "    atomic_numbers = data.z.numpy()\n",
    "    symbols = [atomic_number_to_symbol[i] for i in atomic_numbers]\n",
    "    try:\n",
    "        pg = PointGroup(positions, symbols).get_point_group()\n",
    "    except:\n",
    "        pg = 'C1'\n",
    "    if pg not in pg_losses:\n",
    "        pg_losses[pg]={'loss':0, 'count':0}\n",
    "        \n",
    "    rank = torch.linalg.matrix_rank(data.pos)\n",
    "\n",
    "    for i in range(10):\n",
    "        random_rotation = R.random().as_matrix()\n",
    "        random_translation = np.random.rand(3)\n",
    "        \n",
    "        point_cloud = data.pos\n",
    "        point_cloud = (random_rotation@(point_cloud+random_translation).numpy().T).T\n",
    "        cat_data = data.z.numpy()\n",
    "        SVDA(torch.from_numpy(point_cloud))\n",
    "        new_normalization = SVDA.pointcloud  \n",
    "        loss = compute_wasserstein_distance(normalized_data, new_normalization)\n",
    "\n",
    "        if rank==1:\n",
    "            rank1_loss += loss\n",
    "            rank1_count +=1\n",
    "        elif rank==2:\n",
    "            rank2_loss += loss\n",
    "            rank2_count +=1\n",
    "        else:\n",
    "            rank3_loss += loss\n",
    "            rank3_count +=1\n",
    "            \n",
    "        pg_losses[pg]['loss']+=loss\n",
    "        pg_losses[pg]['count']+=1\n",
    "\n",
    "\n",
    "print(f'Rank 1 Loss: {rank1_loss/(rank1_count+1e-16):.5f}, Rank 2 Loss: {rank2_loss/(rank2_count+1e-16):.5f}, Rank 3 Loss: {rank3_loss/(rank3_count+1e-16):.5f}')\n",
    "\n",
    "for key, dct in pg_losses.items():\n",
    "    val = dct['loss']/dct['count']\n",
    "    print(f'\\tPoint Group {key} : {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3e0e3-81e8-4398-b815-1974c55d76b0",
   "metadata": {},
   "source": [
    "## Equivariant AE (GIAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742628b-e1f1-46e7-962f-b40d19390fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 6565/10000 [20:34<12:36,  4.54it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"../training/models/\")\n",
    "from giae_model import Model\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "qm9 = QM9(root='../datasets/qm9-2.4.0/')\n",
    "model = Model(hidden_dim=256, emb_dim=32, num_layers=5).to(\"cpu\")\n",
    "model.load_state_dict(torch.load('../training/models/giae_model.pth'))  # Load the state dict\n",
    "pg_losses = {}\n",
    "\n",
    "atomic_number_to_symbol = {\n",
    "    1: 'H', 6: 'C', 7: 'N', 8: 'O', 9: 'F'\n",
    "    }\n",
    "\n",
    "\n",
    "rank1_loss, rank1_count = 0,0\n",
    "rank2_loss, rank2_count = 0,0\n",
    "rank3_loss, rank3_count = 0,0\n",
    "\n",
    "for idx,data in enumerate(tqdm(qm9[:10000])):\n",
    "    loader = DataLoader([data], batch_size=1, shuffle=False)\n",
    "    batch = next(iter(loader))\n",
    "    batch.pos = batch.pos - batch.pos.mean(dim=0)\n",
    "    pos_out, perm, vout, rot = model(batch, hard=False)\n",
    "    pos_out = pos_out - pos_out.mean(dim=0)\n",
    "    normalized_data = (pos_out@rot.squeeze()).detach().numpy()\n",
    "        \n",
    "    positions = data.pos.numpy()\n",
    "    atomic_numbers = data.z.numpy()\n",
    "    symbols = [atomic_number_to_symbol[i] for i in atomic_numbers]\n",
    "    try:\n",
    "        pg = PointGroup(positions, symbols).get_point_group()\n",
    "    except:\n",
    "        pg = 'C1'\n",
    "    if pg not in pg_losses:\n",
    "        pg_losses[pg]={'loss':0, 'count':0}\n",
    "        \n",
    "    rank = torch.linalg.matrix_rank(batch.pos)\n",
    "\n",
    "    for i in range(10):\n",
    "        random_rotation = R.random().as_matrix()\n",
    "        random_translation = np.random.rand(3)\n",
    "        \n",
    "        batch.pos = torch.from_numpy((random_rotation@(batch.pos.detach().numpy()+random_translation).T).T).to(torch.float)\n",
    "        pos_out, perm, vout, rot = model(batch, hard=False)\n",
    "        pos_out = pos_out - pos_out.mean(dim=0)\n",
    "        new_normalization = (pos_out@rot.squeeze()).detach().numpy()\n",
    "        loss = compute_wasserstein_distance(normalized_data, new_normalization)\n",
    "\n",
    "        if rank==1:\n",
    "            rank1_loss += loss\n",
    "            rank1_count +=1\n",
    "        elif rank==2:\n",
    "            rank2_loss += loss\n",
    "            rank2_count +=1\n",
    "        else:\n",
    "            rank3_loss += loss\n",
    "            rank3_count +=1\n",
    "            \n",
    "        pg_losses[pg]['loss']+=loss\n",
    "        pg_losses[pg]['count']+=1\n",
    "\n",
    "\n",
    "print(f'Rank 1 Loss: {rank1_loss/(rank1_count+1e-16):.5f}, Rank 2 Loss: {rank2_loss/(rank2_count+1e-16):.5f}, Rank 3 Loss: {rank3_loss/(rank3_count+1e-16):.5f}')\n",
    "\n",
    "for key, dct in pg_losses.items():\n",
    "    val = dct['loss']/dct['count']\n",
    "    print(f'\\tPoint Group {key} : {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57bb40-e357-4c6d-bce0-14b413874bc0",
   "metadata": {},
   "source": [
    "## ASUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cad0a4-9899-4db7-8fac-f45cb3dd2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../pyorbit/')\n",
    "from CategoricalPointCloud import CatFrame as Frame\n",
    "np.random.seed(42)\n",
    "\n",
    "qm9 = QM9(root='../datasets/qm9-2.4.0/')\n",
    "frame = Frame()\n",
    "pg_losses = {}\n",
    "\n",
    "atomic_number_to_symbol = {\n",
    "    1: 'H', 6: 'C', 7: 'N', 8: 'O', 9: 'F'\n",
    "    }\n",
    "\n",
    "\n",
    "rank1_loss, rank1_count = 0,0\n",
    "rank2_loss, rank2_count = 0,0\n",
    "rank3_loss, rank3_count = 0,0\n",
    "\n",
    "for idx,data in enumerate(tqdm(qm9[:10000])):\n",
    "    point_cloud = data.pos\n",
    "    rank = torch.linalg.matrix_rank(point_cloud)\n",
    "    cat_data = data.z.numpy()\n",
    "    normalized_data, rot = frame.get_frame(point_cloud, cat_data)\n",
    "        \n",
    "    positions = data.pos.numpy()\n",
    "    atomic_numbers = data.z.numpy()\n",
    "    symbols = [atomic_number_to_symbol[i] for i in atomic_numbers]\n",
    "    try:\n",
    "        pg = PointGroup(positions, symbols).get_point_group()\n",
    "    except:\n",
    "        pg = 'C1'\n",
    "    if pg not in pg_losses:\n",
    "        pg_losses[pg]={'loss':0, 'count':0}\n",
    "        \n",
    "    rank = torch.linalg.matrix_rank(data.pos)\n",
    "\n",
    "    for i in range(10):\n",
    "        random_rotation = R.random().as_matrix()\n",
    "        random_translation = np.random.rand(3)\n",
    "        \n",
    "        point_cloud = data.pos\n",
    "        point_cloud = (random_rotation@(point_cloud+random_translation).numpy().T).T\n",
    "        cat_data = data.z.numpy()\n",
    "        new_normalization, rot = frame.get_frame(point_cloud, cat_data)\n",
    "        loss = compute_wasserstein_distance(normalized_data, new_normalization)\n",
    "\n",
    "        if rank==1:\n",
    "            rank1_loss += loss\n",
    "            rank1_count +=1\n",
    "        elif rank==2:\n",
    "            rank2_loss += loss\n",
    "            rank2_count +=1\n",
    "        else:\n",
    "            rank3_loss += loss\n",
    "            rank3_count +=1\n",
    "            \n",
    "        pg_losses[pg]['loss']+=loss\n",
    "        pg_losses[pg]['count']+=1\n",
    "\n",
    "\n",
    "print(f'Rank 1 Loss: {rank1_loss/(rank1_count+1e-16):.5f}, Rank 2 Loss: {rank2_loss/(rank2_count+1e-16):.5f}, Rank 3 Loss: {rank3_loss/(rank3_count+1e-16):.5f}')\n",
    "\n",
    "for key, dct in pg_losses.items():\n",
    "    val = dct['loss']/dct['count']\n",
    "    print(f'\\tPoint Group {key} : {val}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umds",
   "language": "python",
   "name": "umds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
